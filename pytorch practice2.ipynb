{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 |step: 0 |train loss:2.3065\n",
      "Epoch: 0 |step: 100 |train loss:0.3436\n",
      "Epoch: 0 |step: 200 |train loss:0.2224\n",
      "Epoch: 0 |step: 300 |train loss:0.1024\n",
      "Epoch: 0 |step: 400 |train loss:0.0766\n",
      "Epoch: 0 |step: 500 |train loss:0.1010\n",
      "Epoch: 0 |step: 600 |train loss:0.0910\n",
      "Epoch: 0 |step: 700 |train loss:0.1434\n",
      "Epoch: 0 |step: 800 |train loss:0.0223\n",
      "Epoch: 0 |step: 900 |train loss:0.1735\n",
      "Epoch: 0 |step: 1000 |train loss:0.0197\n",
      "Epoch: 0 |step: 1100 |train loss:0.0447\n",
      "Epoch: 1 |step: 0 |train loss:0.0953\n",
      "Epoch: 1 |step: 100 |train loss:0.0605\n",
      "Epoch: 1 |step: 200 |train loss:0.0572\n",
      "Epoch: 1 |step: 300 |train loss:0.0290\n",
      "Epoch: 1 |step: 400 |train loss:0.0833\n",
      "Epoch: 1 |step: 500 |train loss:0.0080\n",
      "Epoch: 1 |step: 600 |train loss:0.0385\n",
      "Epoch: 1 |step: 700 |train loss:0.0564\n",
      "Epoch: 1 |step: 800 |train loss:0.0459\n",
      "Epoch: 1 |step: 900 |train loss:0.0697\n",
      "Epoch: 1 |step: 1000 |train loss:0.0069\n",
      "Epoch: 1 |step: 1100 |train loss:0.0187\n",
      "Epoch: 2 |step: 0 |train loss:0.0098\n",
      "Epoch: 2 |step: 100 |train loss:0.0595\n",
      "Epoch: 2 |step: 200 |train loss:0.0062\n",
      "Epoch: 2 |step: 300 |train loss:0.0148\n",
      "Epoch: 2 |step: 400 |train loss:0.0070\n",
      "Epoch: 2 |step: 500 |train loss:0.0021\n",
      "Epoch: 2 |step: 600 |train loss:0.1232\n",
      "Epoch: 2 |step: 700 |train loss:0.0214\n",
      "Epoch: 2 |step: 800 |train loss:0.1112\n",
      "Epoch: 2 |step: 900 |train loss:0.0100\n",
      "Epoch: 2 |step: 1000 |train loss:0.0253\n",
      "Epoch: 2 |step: 1100 |train loss:0.0157\n",
      "Epoch: 3 |step: 0 |train loss:0.0036\n",
      "Epoch: 3 |step: 100 |train loss:0.0280\n",
      "Epoch: 3 |step: 200 |train loss:0.0896\n",
      "Epoch: 3 |step: 300 |train loss:0.0096\n",
      "Epoch: 3 |step: 400 |train loss:0.0202\n",
      "Epoch: 3 |step: 500 |train loss:0.0011\n",
      "Epoch: 3 |step: 600 |train loss:0.0157\n",
      "Epoch: 3 |step: 700 |train loss:0.1175\n",
      "Epoch: 3 |step: 800 |train loss:0.0220\n",
      "Epoch: 3 |step: 900 |train loss:0.0014\n",
      "Epoch: 3 |step: 1000 |train loss:0.0378\n",
      "Epoch: 3 |step: 1100 |train loss:0.0149\n",
      "Epoch: 4 |step: 0 |train loss:0.0293\n",
      "Epoch: 4 |step: 100 |train loss:0.0200\n",
      "Epoch: 4 |step: 200 |train loss:0.0524\n",
      "Epoch: 4 |step: 300 |train loss:0.0112\n",
      "Epoch: 4 |step: 400 |train loss:0.0205\n",
      "Epoch: 4 |step: 500 |train loss:0.0015\n",
      "Epoch: 4 |step: 600 |train loss:0.0014\n",
      "Epoch: 4 |step: 700 |train loss:0.0320\n",
      "Epoch: 4 |step: 800 |train loss:0.0064\n",
      "Epoch: 4 |step: 900 |train loss:0.0585\n",
      "Epoch: 4 |step: 1000 |train loss:0.0110\n",
      "Epoch: 4 |step: 1100 |train loss:0.0046\n",
      "Epoch: 5 |step: 0 |train loss:0.0011\n",
      "Epoch: 5 |step: 100 |train loss:0.0037\n",
      "Epoch: 5 |step: 200 |train loss:0.0043\n",
      "Epoch: 5 |step: 300 |train loss:0.0013\n",
      "Epoch: 5 |step: 400 |train loss:0.0203\n",
      "Epoch: 5 |step: 500 |train loss:0.0564\n",
      "Epoch: 5 |step: 600 |train loss:0.0246\n",
      "Epoch: 5 |step: 700 |train loss:0.0307\n",
      "Epoch: 5 |step: 800 |train loss:0.0130\n",
      "Epoch: 5 |step: 900 |train loss:0.0224\n",
      "Epoch: 5 |step: 1000 |train loss:0.0022\n",
      "Epoch: 5 |step: 1100 |train loss:0.0083\n",
      "Epoch: 6 |step: 0 |train loss:0.0058\n",
      "Epoch: 6 |step: 100 |train loss:0.0654\n",
      "Epoch: 6 |step: 200 |train loss:0.0012\n",
      "Epoch: 6 |step: 300 |train loss:0.0169\n",
      "Epoch: 6 |step: 400 |train loss:0.0062\n",
      "Epoch: 6 |step: 500 |train loss:0.1597\n",
      "Epoch: 6 |step: 600 |train loss:0.0037\n",
      "Epoch: 6 |step: 700 |train loss:0.0005\n",
      "Epoch: 6 |step: 800 |train loss:0.0011\n",
      "Epoch: 6 |step: 900 |train loss:0.0309\n",
      "Epoch: 6 |step: 1000 |train loss:0.1065\n",
      "Epoch: 6 |step: 1100 |train loss:0.0035\n",
      "Epoch: 7 |step: 0 |train loss:0.0051\n",
      "Epoch: 7 |step: 100 |train loss:0.0051\n",
      "Epoch: 7 |step: 200 |train loss:0.0004\n",
      "Epoch: 7 |step: 300 |train loss:0.0012\n",
      "Epoch: 7 |step: 400 |train loss:0.0009\n",
      "Epoch: 7 |step: 500 |train loss:0.0013\n",
      "Epoch: 7 |step: 600 |train loss:0.0041\n",
      "Epoch: 7 |step: 700 |train loss:0.0256\n",
      "Epoch: 7 |step: 800 |train loss:0.0027\n",
      "Epoch: 7 |step: 900 |train loss:0.0706\n",
      "Epoch: 7 |step: 1000 |train loss:0.0010\n",
      "Epoch: 7 |step: 1100 |train loss:0.0105\n",
      "Epoch: 8 |step: 0 |train loss:0.0147\n",
      "Epoch: 8 |step: 100 |train loss:0.0028\n",
      "Epoch: 8 |step: 200 |train loss:0.0012\n",
      "Epoch: 8 |step: 300 |train loss:0.0002\n",
      "Epoch: 8 |step: 400 |train loss:0.0006\n",
      "Epoch: 8 |step: 500 |train loss:0.0027\n",
      "Epoch: 8 |step: 600 |train loss:0.0012\n",
      "Epoch: 8 |step: 700 |train loss:0.0001\n",
      "Epoch: 8 |step: 800 |train loss:0.0365\n"
     ]
    }
   ],
   "source": [
    "import torch           #使用pytorch框架\n",
    "import torch.nn as nn  #使用類神經網路模塊所有類神經網路的基本類別\n",
    "from torch.autograd import Variable   #variable像一個容器,可以容納tensor在裡面計算\n",
    "import torch.utils.data as Data     #隨機抽取data的工具,隨機mini-batch\n",
    "import torchvision    #用來生成圖片影片的數據集,流行的pretrained model\n",
    "import matplotlib.pyplot as plt   #輸出圖片工具包\n",
    "\n",
    "\n",
    "EPOCH = 10                #全部data訓練10次\n",
    "BATCH_SIZE = 50           #每次訓練隨機丟50張圖像進去\n",
    "LR =0.001                 #learning rate\n",
    "DOWNLOAD_MNIST = False    #第一次用要先下載data,所以是True\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(), \n",
    "    #把灰階從0~255壓縮到0~1\n",
    "    download=DOWNLOAD_MNIST\n",
    ")\n",
    "\n",
    "\n",
    "print(train_data.train_data.size())\n",
    "print(train_data.train_labels.size())\n",
    "\n",
    "\n",
    "plt.imshow(train_data.train_data[4].numpy(),cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[0])\n",
    "plt.show()\n",
    "\n",
    "#show 出train data set 中第一張影像\n",
    "\n",
    "train_loader = Data.DataLoader(dataset = train_data, batch_size = BATCH_SIZE, shuffle=True)\n",
    "#shuffle是隨機從data裡讀去資料.\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/', \n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=DOWNLOAD_MNIST,\n",
    ")\n",
    "\n",
    "test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1).float(), requires_grad=False)\n",
    "#requires_grad=False 不參與反向傳播,test data 不用做\n",
    " \n",
    "test_y = test_data.test_labels\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "#搭建網路的起手式,nn.module是所有網路的基類.\n",
    "#我們開始定義一系列網路如下：  #train data ＝ (1,28,28)      \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(           \n",
    "            #convolution2D\n",
    "                in_channels=1,  \n",
    "                #input channel(EX:RGB)\n",
    "                out_channels=16, \n",
    "                #output feature maps\n",
    "                kernel_size=5,   \n",
    "                #filter大小\n",
    "                stride=1,        \n",
    "                #每次convolution移動多少\n",
    "                padding=2,       \n",
    "                #在圖片旁邊補0                       \n",
    "            ),\n",
    "            nn.ReLU(), #activation function #(16,28,28)\n",
    "            nn.MaxPool2d(kernel_size=2), #(16,14,14)\n",
    "        )\n",
    "        #以上為一層conv + ReLu + maxpool\n",
    "        \n",
    "        #快速寫法：\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32,5,1,2),  #(32,14,14)\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2)   #(32,7,7)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Linear(32*7*7, 10) #10=0~9\n",
    "       \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "       \n",
    "#forward流程:\n",
    "#x = x.view(x.size(0), -1) 展平data  \n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#優化器使用Adam\n",
    "#loss_func 使用CrossEntropy（classification task）\n",
    "\n",
    "\n",
    "\n",
    "if_use_gpu = 0\n",
    "\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        b_x = Variable(x, requires_grad=False)\n",
    "        b_y = Variable(y, requires_grad=False)\n",
    "#決定跑幾個epoch,enumerate把load進來的data列出來成（x,y）\n",
    "\n",
    "        if if_use_gpu:\n",
    "            b_x = b_x.cuda()\n",
    "            b_y = b_y.cuda()\n",
    "#使用cuda加速        \n",
    "        output = cnn(b_x)          #把data丟進網路中\n",
    "        loss = loss_function(output, b_y)\n",
    "        optimizer.zero_grad()      #計算loss,初始梯度\n",
    "        loss.backward()            #反向傳播\n",
    "        optimizer.step()       \n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch:', epoch, '|step:', step, '|train loss:%.4f'%loss.data)\n",
    "        \n",
    "        #每100steps輸出一次train loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

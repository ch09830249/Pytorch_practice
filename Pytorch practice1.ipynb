{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baa9a0cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU State: cpu\n",
      "Net(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=32, out_features=10, bias=True)\n",
      "    (7): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n",
      "[1/3, 100/938] loss: 0.114\n",
      "[1/3, 200/938] loss: 0.220\n",
      "[1/3, 300/938] loss: 0.299\n",
      "[1/3, 400/938] loss: 0.346\n",
      "[1/3, 500/938] loss: 0.383\n",
      "[1/3, 600/938] loss: 0.414\n",
      "[1/3, 700/938] loss: 0.442\n",
      "[1/3, 800/938] loss: 0.466\n",
      "[1/3, 900/938] loss: 0.487\n",
      "[1/3, 938/938] loss: 0.495\n",
      "[2/3, 100/938] loss: 0.020\n",
      "[2/3, 200/938] loss: 0.039\n",
      "[2/3, 300/938] loss: 0.058\n",
      "[2/3, 400/938] loss: 0.077\n",
      "[2/3, 500/938] loss: 0.093\n",
      "[2/3, 600/938] loss: 0.109\n",
      "[2/3, 700/938] loss: 0.126\n",
      "[2/3, 800/938] loss: 0.142\n",
      "[2/3, 900/938] loss: 0.158\n",
      "[2/3, 938/938] loss: 0.164\n",
      "[3/3, 100/938] loss: 0.014\n",
      "[3/3, 200/938] loss: 0.029\n",
      "[3/3, 300/938] loss: 0.044\n",
      "[3/3, 400/938] loss: 0.057\n",
      "[3/3, 500/938] loss: 0.072\n",
      "[3/3, 600/938] loss: 0.085\n",
      "[3/3, 700/938] loss: 0.098\n",
      "[3/3, 800/938] loss: 0.111\n",
      "[3/3, 900/938] loss: 0.124\n",
      "[3/3, 938/938] loss: 0.129\n",
      "Training Finished.\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "Accuracy of 0: 0.967105\n",
      "Accuracy of 1: 0.978378\n",
      "Accuracy of 2: 0.860465\n",
      "Accuracy of 3: 0.916667\n",
      "Accuracy of 4: 0.960452\n",
      "Accuracy of 5: 0.904762\n",
      "Accuracy of 6: 0.921875\n",
      "Accuracy of 7: 0.932927\n",
      "Accuracy of 8: 0.951049\n",
      "Accuracy of 9: 0.856287\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as dset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# GPU\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,)),]\n",
    ")\n",
    "\n",
    "# Data\n",
    "trainSet = datasets.MNIST(root='MNIST', download=True, train=True, transform=transform)\n",
    "testSet = datasets.MNIST(root='MNIST', download=True, train=False, transform=transform)\n",
    "trainLoader = dset.DataLoader(trainSet, batch_size=64, shuffle=True)\n",
    "testLoader = dset.DataLoader(testSet, batch_size=64, shuffle=False)\n",
    "\n",
    "# Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_features=784, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=10),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)\n",
    "\n",
    "# Parameters\n",
    "epochs = 3\n",
    "lr = 0.002\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.002, momentum=0.9)\n",
    "\n",
    "# Train\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for times, data in enumerate(trainLoader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.view(inputs.shape[0], -1)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Foward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if times % 100 == 99 or times+1 == len(trainLoader):\n",
    "            print('[%d/%d, %d/%d] loss: %.3f' % (epoch+1, epochs, times+1, len(trainLoader), running_loss/2000))\n",
    "\n",
    "print('Training Finished.')\n",
    "\n",
    "# Test\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs = inputs.view(inputs.shape[0], -1)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100*correct / total))\n",
    "\n",
    "class_correct = [0 for i in range(10)]\n",
    "class_total = [0 for i in range(10)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.view(inputs.shape[0], -1)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        '''print(outputs)'''\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(10):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "            '''print(class_correct)\n",
    "            print(class_total)'''\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %d: %3f' % (i, (class_correct[i]/class_total[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23586929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU state: cpu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "[1/3, 100/6250] loss: 0.115\n",
      "[1/3, 200/6250] loss: 0.230\n",
      "[1/3, 300/6250] loss: 0.345\n",
      "[1/3, 400/6250] loss: 0.460\n",
      "[1/3, 500/6250] loss: 0.575\n",
      "[1/3, 600/6250] loss: 0.689\n",
      "[1/3, 700/6250] loss: 0.803\n",
      "[1/3, 800/6250] loss: 0.916\n",
      "[1/3, 900/6250] loss: 1.029\n",
      "[1/3, 1000/6250] loss: 1.138\n",
      "[1/3, 1100/6250] loss: 1.245\n",
      "[1/3, 1200/6250] loss: 1.352\n",
      "[1/3, 1300/6250] loss: 1.455\n",
      "[1/3, 1400/6250] loss: 1.555\n",
      "[1/3, 1500/6250] loss: 1.656\n",
      "[1/3, 1600/6250] loss: 1.755\n",
      "[1/3, 1700/6250] loss: 1.853\n",
      "[1/3, 1800/6250] loss: 1.950\n",
      "[1/3, 1900/6250] loss: 2.047\n",
      "[1/3, 2000/6250] loss: 2.143\n",
      "[1/3, 2100/6250] loss: 2.235\n",
      "[1/3, 2200/6250] loss: 2.328\n",
      "[1/3, 2300/6250] loss: 2.421\n",
      "[1/3, 2400/6250] loss: 2.511\n",
      "[1/3, 2500/6250] loss: 2.601\n",
      "[1/3, 2600/6250] loss: 2.692\n",
      "[1/3, 2700/6250] loss: 2.780\n",
      "[1/3, 2800/6250] loss: 2.871\n",
      "[1/3, 2900/6250] loss: 2.959\n",
      "[1/3, 3000/6250] loss: 3.046\n",
      "[1/3, 3100/6250] loss: 3.134\n",
      "[1/3, 3200/6250] loss: 3.218\n",
      "[1/3, 3300/6250] loss: 3.307\n",
      "[1/3, 3400/6250] loss: 3.394\n",
      "[1/3, 3500/6250] loss: 3.478\n",
      "[1/3, 3600/6250] loss: 3.561\n",
      "[1/3, 3700/6250] loss: 3.648\n",
      "[1/3, 3800/6250] loss: 3.733\n",
      "[1/3, 3900/6250] loss: 3.815\n",
      "[1/3, 4000/6250] loss: 3.896\n",
      "[1/3, 4100/6250] loss: 3.977\n",
      "[1/3, 4200/6250] loss: 4.060\n",
      "[1/3, 4300/6250] loss: 4.141\n",
      "[1/3, 4400/6250] loss: 4.223\n",
      "[1/3, 4500/6250] loss: 4.304\n",
      "[1/3, 4600/6250] loss: 4.381\n",
      "[1/3, 4700/6250] loss: 4.463\n",
      "[1/3, 4800/6250] loss: 4.544\n",
      "[1/3, 4900/6250] loss: 4.627\n",
      "[1/3, 5000/6250] loss: 4.706\n",
      "[1/3, 5100/6250] loss: 4.782\n",
      "[1/3, 5200/6250] loss: 4.861\n",
      "[1/3, 5300/6250] loss: 4.938\n",
      "[1/3, 5400/6250] loss: 5.015\n",
      "[1/3, 5500/6250] loss: 5.091\n",
      "[1/3, 5600/6250] loss: 5.171\n",
      "[1/3, 5700/6250] loss: 5.248\n",
      "[1/3, 5800/6250] loss: 5.324\n",
      "[1/3, 5900/6250] loss: 5.401\n",
      "[1/3, 6000/6250] loss: 5.479\n",
      "[1/3, 6100/6250] loss: 5.555\n",
      "[1/3, 6200/6250] loss: 5.628\n",
      "[1/3, 6250/6250] loss: 5.665\n",
      "[2/3, 100/6250] loss: 0.075\n",
      "[2/3, 200/6250] loss: 0.149\n",
      "[2/3, 300/6250] loss: 0.222\n",
      "[2/3, 400/6250] loss: 0.298\n",
      "[2/3, 500/6250] loss: 0.374\n",
      "[2/3, 600/6250] loss: 0.447\n",
      "[2/3, 700/6250] loss: 0.518\n",
      "[2/3, 800/6250] loss: 0.591\n",
      "[2/3, 900/6250] loss: 0.663\n",
      "[2/3, 1000/6250] loss: 0.738\n",
      "[2/3, 1100/6250] loss: 0.811\n",
      "[2/3, 1200/6250] loss: 0.885\n",
      "[2/3, 1300/6250] loss: 0.956\n",
      "[2/3, 1400/6250] loss: 1.028\n",
      "[2/3, 1500/6250] loss: 1.097\n",
      "[2/3, 1600/6250] loss: 1.169\n",
      "[2/3, 1700/6250] loss: 1.241\n",
      "[2/3, 1800/6250] loss: 1.312\n",
      "[2/3, 1900/6250] loss: 1.389\n",
      "[2/3, 2000/6250] loss: 1.462\n",
      "[2/3, 2100/6250] loss: 1.533\n",
      "[2/3, 2200/6250] loss: 1.606\n",
      "[2/3, 2300/6250] loss: 1.677\n",
      "[2/3, 2400/6250] loss: 1.750\n",
      "[2/3, 2500/6250] loss: 1.820\n",
      "[2/3, 2600/6250] loss: 1.891\n",
      "[2/3, 2700/6250] loss: 1.961\n",
      "[2/3, 2800/6250] loss: 2.032\n",
      "[2/3, 2900/6250] loss: 2.103\n",
      "[2/3, 3000/6250] loss: 2.171\n",
      "[2/3, 3100/6250] loss: 2.240\n",
      "[2/3, 3200/6250] loss: 2.310\n",
      "[2/3, 3300/6250] loss: 2.383\n",
      "[2/3, 3400/6250] loss: 2.450\n",
      "[2/3, 3500/6250] loss: 2.519\n",
      "[2/3, 3600/6250] loss: 2.589\n",
      "[2/3, 3700/6250] loss: 2.661\n",
      "[2/3, 3800/6250] loss: 2.729\n",
      "[2/3, 3900/6250] loss: 2.798\n",
      "[2/3, 4000/6250] loss: 2.872\n",
      "[2/3, 4100/6250] loss: 2.943\n",
      "[2/3, 4200/6250] loss: 3.012\n",
      "[2/3, 4300/6250] loss: 3.078\n",
      "[2/3, 4400/6250] loss: 3.147\n",
      "[2/3, 4500/6250] loss: 3.217\n",
      "[2/3, 4600/6250] loss: 3.289\n",
      "[2/3, 4700/6250] loss: 3.357\n",
      "[2/3, 4800/6250] loss: 3.429\n",
      "[2/3, 4900/6250] loss: 3.501\n",
      "[2/3, 5000/6250] loss: 3.566\n",
      "[2/3, 5100/6250] loss: 3.634\n",
      "[2/3, 5200/6250] loss: 3.701\n",
      "[2/3, 5300/6250] loss: 3.767\n",
      "[2/3, 5400/6250] loss: 3.834\n",
      "[2/3, 5500/6250] loss: 3.903\n",
      "[2/3, 5600/6250] loss: 3.967\n",
      "[2/3, 5700/6250] loss: 4.036\n",
      "[2/3, 5800/6250] loss: 4.102\n",
      "[2/3, 5900/6250] loss: 4.167\n",
      "[2/3, 6000/6250] loss: 4.237\n",
      "[2/3, 6100/6250] loss: 4.304\n",
      "[2/3, 6200/6250] loss: 4.370\n",
      "[2/3, 6250/6250] loss: 4.404\n",
      "[3/3, 100/6250] loss: 0.067\n",
      "[3/3, 200/6250] loss: 0.134\n",
      "[3/3, 300/6250] loss: 0.201\n",
      "[3/3, 400/6250] loss: 0.266\n",
      "[3/3, 500/6250] loss: 0.334\n",
      "[3/3, 600/6250] loss: 0.396\n",
      "[3/3, 700/6250] loss: 0.465\n",
      "[3/3, 800/6250] loss: 0.533\n",
      "[3/3, 900/6250] loss: 0.597\n",
      "[3/3, 1000/6250] loss: 0.661\n",
      "[3/3, 1100/6250] loss: 0.724\n",
      "[3/3, 1200/6250] loss: 0.788\n",
      "[3/3, 1300/6250] loss: 0.849\n",
      "[3/3, 1400/6250] loss: 0.913\n",
      "[3/3, 1500/6250] loss: 0.980\n",
      "[3/3, 1600/6250] loss: 1.043\n",
      "[3/3, 1700/6250] loss: 1.106\n",
      "[3/3, 1800/6250] loss: 1.170\n",
      "[3/3, 1900/6250] loss: 1.235\n",
      "[3/3, 2000/6250] loss: 1.298\n",
      "[3/3, 2100/6250] loss: 1.363\n",
      "[3/3, 2200/6250] loss: 1.424\n",
      "[3/3, 2300/6250] loss: 1.486\n",
      "[3/3, 2400/6250] loss: 1.552\n",
      "[3/3, 2500/6250] loss: 1.615\n",
      "[3/3, 2600/6250] loss: 1.679\n",
      "[3/3, 2700/6250] loss: 1.742\n",
      "[3/3, 2800/6250] loss: 1.808\n",
      "[3/3, 2900/6250] loss: 1.869\n",
      "[3/3, 3000/6250] loss: 1.934\n",
      "[3/3, 3100/6250] loss: 1.999\n",
      "[3/3, 3200/6250] loss: 2.064\n",
      "[3/3, 3300/6250] loss: 2.128\n",
      "[3/3, 3400/6250] loss: 2.191\n",
      "[3/3, 3500/6250] loss: 2.252\n",
      "[3/3, 3600/6250] loss: 2.316\n",
      "[3/3, 3700/6250] loss: 2.378\n",
      "[3/3, 3800/6250] loss: 2.443\n",
      "[3/3, 3900/6250] loss: 2.507\n",
      "[3/3, 4000/6250] loss: 2.569\n",
      "[3/3, 4100/6250] loss: 2.632\n",
      "[3/3, 4200/6250] loss: 2.695\n",
      "[3/3, 4300/6250] loss: 2.758\n",
      "[3/3, 4400/6250] loss: 2.824\n",
      "[3/3, 4500/6250] loss: 2.887\n",
      "[3/3, 4600/6250] loss: 2.949\n",
      "[3/3, 4700/6250] loss: 3.016\n",
      "[3/3, 4800/6250] loss: 3.079\n",
      "[3/3, 4900/6250] loss: 3.141\n",
      "[3/3, 5000/6250] loss: 3.203\n",
      "[3/3, 5100/6250] loss: 3.267\n",
      "[3/3, 5200/6250] loss: 3.330\n",
      "[3/3, 5300/6250] loss: 3.390\n",
      "[3/3, 5400/6250] loss: 3.454\n",
      "[3/3, 5500/6250] loss: 3.518\n",
      "[3/3, 5600/6250] loss: 3.581\n",
      "[3/3, 5700/6250] loss: 3.639\n",
      "[3/3, 5800/6250] loss: 3.704\n",
      "[3/3, 5900/6250] loss: 3.764\n",
      "[3/3, 6000/6250] loss: 3.825\n",
      "[3/3, 6100/6250] loss: 3.884\n",
      "[3/3, 6200/6250] loss: 3.944\n",
      "[3/3, 6250/6250] loss: 3.972\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test inputs: 54 %\n",
      "Accuracy of plane : 71 %\n",
      "Accuracy of   car : 57 %\n",
      "Accuracy of  bird : 51 %\n",
      "Accuracy of   cat : 33 %\n",
      "Accuracy of  deer : 45 %\n",
      "Accuracy of   dog : 36 %\n",
      "Accuracy of  frog : 71 %\n",
      "Accuracy of horse : 61 %\n",
      "Accuracy of  ship : 59 %\n",
      "Accuracy of truck : 58 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# GPU\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU state:', device)\n",
    "\n",
    "# Cifar-10 data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Data\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "testLoader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "# Data classes\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model structure\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)\n",
    "\n",
    "# Parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "epochs = 3\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "# Train\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for times, data in enumerate(trainLoader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if times % 100 == 99 or times+1 == len(trainLoader):\n",
    "            print('[%d/%d, %d/%d] loss: %.3f' % (epoch+1, epochs, times+1, len(trainLoader), running_loss/2000))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Test\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test inputs: %d %%' % (100 * correct / total))\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(8):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841d018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
